# 05-数组：为什么很多编程语言的数组都是从0开始编号？

## 内容摘要

### 如何实现随机访问？

**数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据**

1. 线性表（Linear List）

- 线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有**前和后**两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

![](_v_images/20200527203148258_31314.png =571x)

- 而与它相对立的概念是**非线性表**，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

2. 连续的内存空间和相同类型的数据

正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“**随机访问**”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的**数据搬移**工作。

说到数据的访问，那你知道数组是如何实现**根据下标随机访问数组元素**的吗？一个长度为 10 的 int 类型的数组 int[] a = new int[10]。在图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。

![](_v_images/20200527203654060_21800.png =571x)

计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

```
a[i]_address = base_address + i * data_type_size
```

其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。

数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持**随机访问，根据下标随机访问的时间复杂度为 O(1)**。

### 低效的“插入”和“删除”

1. 插入

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以**最坏时间复杂度是 O(n)**。 因为我们在每个位置插入元素的概率是一样的，所以**平均情况时间复杂度为 (1+2+…n)/n=O(n)**

如果数组中的数据是**有序**的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，**如果数组中存储的数据并没有任何规律**，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，**为了避免大规模的数据搬移**，我们还有一个简单的办法就是，**直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置**。如图

![](_v_images/20200527204458647_4788.png =685x)

**利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)**。这个处理思想在**快排**中也会用到

2. 删除

跟插入数据类似，要删除第 k 个位置的数据，为了内存的连续性，也需要**搬移数据**，不然中间就会出现空洞，内存就不连续了。如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

在某些**特殊场景**下，我们并不一定非得追求数组中数据的连续性。如图，依次删除a，b，c，**为了避免 d，e，f，g，h 这几个数据会被搬移三次**，可以**先记录下已经删除的数据**。每次的删除操作只是记录数据已经被删除。**当数组没有更多空间存储数据时，再触发执行一次真正的删除操作**，这样就大大减少了删除操作导致的数据搬移。

![](_v_images/20200527204823006_5177.png =685x)

**JVM 标记清除垃圾回收算法的核心思想**

### 警惕数组的访问越界问题

```c
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```

数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a[3]访问越界

在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。

### 容器能否完全替代数组？

针对数组类型，很多语言都提供了**容器类**，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，**什么时候适合用数组，什么时候适合用容器呢**？

Java 语言来举例。ArrayList 最大的优势就是**可以将很多数组操作的细节封装起来**。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是**支持动态扩容**。数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。**如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑**。每次存储空间不够的时候，**它都会将空间自动扩容为 1.5 倍大小**。不过，这里需要注意一点，因为**扩容操作涉及内存申请和数据搬移，是比较耗时的**。所以，如果事先能确定需要存储的数据大小，最好在**创建 ArrayList 的时候事先指定数据大小**。

对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。
做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

### 为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式

```
a[k]_address = base_address + k * type_size
```

如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：

```
a[k]_address = base_address + (k-1)*type_size
```

对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是**多了一次减法指令**

最主要的原因可能是历史原因。C 语言设计者用 0 开始计数数组下标

## 总结与思考


## 评论

**JVM标记清除算法：**

大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

**二维数组内存寻址：**

对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：

```
address = base_address + ( i * n + j) * type_size
```

另外，对于数组访问越界造成无限循环，我理解是编译器的问题，对于不同的编译器，在内存分配时，会按照内存地址递增或递减的方式进行分配。老师的程序，如果是内存地址递减的方式，就会造成无限循环。

----
对文中示例的无限循环有疑问的同学，建议去查函数调用的栈桢结构细节（操作系统或计算机体系结构的教材应该会讲到）。

函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。

----
例子中死循环的问题跟编译器分配内存和字节对齐有关 数组3个元素 加上一个变量a 。4个整数刚好能满足8字节对齐 所以i的地址恰好跟着a2后面 导致死循环。。如果数组本身有4个元素 则这里不会出现死循环。。因为编译器64位操作系统下 默认会进行8字节对齐 变量i的地址就不紧跟着数组后面了。

----

对于死循环那个问题，要了解栈这个东西。栈是向下增长的，首先压栈的i，a[2]，a[1]，a[0]，这是我在我vc上调试查看汇编的时候看到的压栈顺序。相当于访问a[3]的时候，是在访问i变量，而此时i变量的地址是数组当前进程的，所以进行修改的时候，操作系统并不会终止进程。

----

老师，您好，个人觉得您举例的内存越界的循环应该限制在x86架构的小端模式，在别的架构平台上的大端模式应该不是这样的！

----

无限循环的问题，我认为内存分配是从后往前分配的。例如，在Excel中从上往下拉4个格子，变量i会先被分配到第4个格子的内存，然后变量arr往上数分配3个格子的内存，但arr的数据是从分配3个格子的第一个格子从上往下存储数据的，当访问第3索引时，这时刚好访问到第4个格子变量i的内存。
不知道对不对，望指正！
